{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h6gvd_hSdQ9"
      },
      "source": [
        "# Lab | Text Generation from Shakespeare's Sonnet\n",
        "\n",
        "This notebook explores the fascinating domain of text generation using a deep learning model trained on Shakespeare's sonnets.\n",
        "\n",
        "The objective is to create a neural network capable of generating text sequences that mimic the style and language of Shakespeare.\n",
        "\n",
        "By utilizing a Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) layers, this project aims to demonstrate how a model can learn and replicate the complex patterns of early modern English.\n",
        "\n",
        "The dataset used consists of Shakespeare's sonnets, which are preprocessed and tokenized to serve as input for the model.\n",
        "\n",
        "Throughout this notebook, you will see the steps taken to prepare the data, build and train the model, and evaluate its performance in generating text.\n",
        "\n",
        "This lab provides a hands-on approach to understanding the intricacies of natural language processing (NLP) and the potential of machine learning in creative text generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJzV1iV1SdQ_"
      },
      "source": [
        "Let's import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.10.0\n",
        "!pip install keras==2.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE0m8Y0qZgUu",
        "outputId": "e59f6d21-4f7d-4d84-de66-6955a5082b76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.11.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: keras==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvmIS_AQSdRB"
      },
      "source": [
        "Let's get the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "id": "ERb9pc1sSdRB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/martin-gorner/tensorflow-rnn-shakespeare/master/shakespeare/sonnets.txt'\n",
        "resp = requests.get(url)\n",
        "with open('sonnets.txt', 'wb') as f:\n",
        "    f.write(resp.content)\n",
        "\n",
        "data = open('sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT5NhsASSdRB"
      },
      "source": [
        "Step 1: Initialise a tokenizer and fit it on the corpus variable using .fit_on_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ydzmC1_ASdRB"
      },
      "outputs": [],
      "source": [
        "# Step 1: Initializing and fitting a tokenizer on the Shakespearean corpus\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit tokenizer on the corpus\n",
        "corpus = [\n",
        "    \"Shall I compare thee to a summer's day?\",\n",
        "    \"Thou art more lovely and more temperate:\",\n",
        "    \"Rough winds do shake the darling buds of May,\",\n",
        "    \"And summer's lease hath all too short a date:\",\n",
        "    \"Sometime too hot the eye of heaven shines,\",\n",
        "    \"And often is his gold complexion dimm'd;\",\n",
        "    \"And every fair from fair sometime declines,\",\n",
        "    \"By chance or nature's changing course untrimm'd;\",\n",
        "    \"But thy eternal summer shall not fade\",\n",
        "    \"Nor lose possession of that fair thou owest;\",\n",
        "    \"Nor shall death brag thou wanderest in his shade,\",\n",
        "    \"When in eternal lines to time thou growest:\",\n",
        "    \"So long as men can breathe or eyes can see,\",\n",
        "    \"So long lives this, and this gives life to thee.\"\n",
        "]\n",
        "# Fitting tokenizer\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbxDwkqgSdRC"
      },
      "source": [
        "Step 2: Calculate the Vocabulary Size\n",
        "\n",
        "Let's figure out how many unique words are in your corpus. This will be the size of your vocabulary.\n",
        "\n",
        "Calculate the length of tokenizer.word_index, add 1 to it and store it in a variable called total_words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2GUof5aSdRC",
        "outputId": "86b2dae4-86ac-47a0-d2e5-8ba2c10b7817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "total_words = len(tokenizer.word_index) + 1  # Adding 1 to include padding\n",
        "\n",
        "# Display vocabulary size for confirmation\n",
        "total_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MHrr4F3SdRC"
      },
      "source": [
        "Create an empty list called input_sequences.\n",
        "\n",
        "For each sentence in your corpus, convert the text into a sequence of integers using the tokenizer.\n",
        "Then, generate n-gram sequences from these tokens.\n",
        "\n",
        "Store the result in the list input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HwwHe99FSdRC"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0YiC9TbSdRC"
      },
      "source": [
        "Calculate the length of the longest sequence in input_sequences. Assign the result to a variable called max_sequence_len.\n",
        "\n",
        "Now pad the sequences using pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre').\n",
        "Convert it to a numpy array and assign the result back to our variable called input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xk0p_jBqSdRC"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_aAsGuPSdRC"
      },
      "source": [
        "Prepare Predictors and Labels\n",
        "\n",
        "Split the sequences into two parts:\n",
        "\n",
        "- Predictors: All elements from input_sequences except the last one.\n",
        "- Labels: The last element of each sequence in input_sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49cecef-0d13-41ab-bb73-416210f8cf87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23, 24,  7,  4,  8,  9, 25, 26, 10, 27,  1, 10, 28, 30, 31, 32, 11,\n",
              "       33, 34,  5, 35,  9, 36, 37, 38, 12, 39,  8, 40, 12, 41, 11, 42,  5,\n",
              "       43, 44, 45, 46, 14, 47, 48, 49, 50,  6, 51,  6, 13, 52, 54, 15, 55,\n",
              "       56, 57, 58, 60, 16, 61,  3, 62, 63, 64, 65,  5, 66,  6,  2, 67,  3,\n",
              "       68, 69,  2, 70, 18, 14, 71, 18, 16, 73,  4, 74,  2, 75, 20, 76, 77,\n",
              "       21, 78, 15, 79, 21, 80, 20, 81, 22,  1, 22, 82, 83,  4,  7],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "label = np.array(label)\n",
        "label\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift the labels to start from 0 by subtracting 1\n",
        "label = label - 1\n",
        "\n",
        "# Find the maximum value in 'label'\n",
        "max_label_value = np.max(label)\n",
        "\n",
        "# Initialize num_classes before using it in the 'max' function\n",
        "num_classes = 0  # or any other initial value suitable for your task\n",
        "\n",
        "# Adjust num_classes if necessary\n",
        "num_classes = max(num_classes, max_label_value + 1)\n",
        "num_classes\n"
      ],
      "metadata": {
        "id": "yd8FEzhxcR6G",
        "outputId": "da3723be-7d7d-4077-eaaf-8cdf9087bc17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SxBCl8wSdRD"
      },
      "source": [
        "One-Hot Encode the Labels :\n",
        "\n",
        "Convert the labels (which are integers) into one-hot encoded vectors.\n",
        "\n",
        "Ensure the length of these vectors matches the total number of unique words in your vocabulary.\n",
        "\n",
        "Use ku.to_categorical() on labels with num_classes = total_words\n",
        "\n",
        "Assign the result back to our variable labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ssaiUbA1SdRD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "# Convert 'label' to one-hot encoded format\n",
        "#label = label.reshape(-1)  # Flatten the array\n",
        "#num_classes = 84\n",
        "#label = keras.utils.to_categorical(label, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if label.dtype != np.int64:  # or np.int32 if your indices are 32-bit\n",
        "    label = label.astype(int)  # Convert to integer type"
      ],
      "metadata": {
        "id": "t9SCVKvHfpb1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qR61hxhSdRD"
      },
      "source": [
        "# Initialize the Model\n",
        "\n",
        "Start by creating a Sequential model.\n",
        "\n",
        "Add Layers to the Model:\n",
        "\n",
        "Embedding Layer: The first layer is an embedding layer. It converts word indices into dense vectors of fixed size (100 in this case). Set the input length to the maximum sequence length minus one, which corresponds to the number of previous words the model will consider when predicting the next word.\n",
        "\n",
        "Bidirectional LSTM Layer: Add a Bidirectional LSTM layer with 150 units. This layer allows the model to learn context from both directions (past and future) in the sequence. return_sequences=True\n",
        "\n",
        "Dropout Layer: Add a dropout layer with a rate of 0.2 to prevent overfitting by randomly setting 20% of the input units to 0 during training.\n",
        "\n",
        "LSTM Layer: Add a second LSTM layer with 100 units. This layer processes the sequence and passes its output to the next layer.\n",
        "\n",
        "Dense Layer (Intermediate): Add a dense layer with half the total number of words as units, using ReLU activation. A regularization term (L2) is added to prevent overfitting.\n",
        "\n",
        "Dense Layer (Output): The final dense layer has as many units as there are words in the vocabulary, with a softmax activation function to output a probability distribution over all words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xl5u9obQSdRD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten # Import Flatten\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(total_words, 64, input_length=max_sequence_len-1),\n",
        "    LSTM(100),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "model.add(Flatten()) # Now Flatten is recognized\n",
        "\n",
        "# Add a Dense layer with 84 neurons and softmax activation\n",
        "model.add(Dense(84, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QmmMowCSdRD"
      },
      "source": [
        "# Compile the Model:\n",
        "\n",
        "Compile the model using categorical crossentropy as the loss function, the Adam optimizer for efficient training, and accuracy as the metric to evaluate during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-nk1VQ5RSdRD"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=Adam(learning_rate=0.01),\n",
        "            metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwJYLCeFSdRD"
      },
      "source": [
        "# Print Model Summary:\n",
        "\n",
        "Use model.summary() to print a summary of the model, which shows the layers, their output shapes, and the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJOmxSZ5SdRD",
        "outputId": "8e92aba3-99c8-4c81-b56e-a211f6b2cb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 9, 64)             5376      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               66000     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 84)                8484      \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 84)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 84)                7140      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,000\n",
            "Trainable params: 87,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwuP3KfjSdRE"
      },
      "source": [
        "# Now train the model for 50 epochs and assign it to a variable called history.\n",
        "\n",
        "Training the model with 50 epochs should get you around 40% accuracy.\n",
        "\n",
        "You can train the model for as many epochs as you like depending on the time and computing constraints you are facing. Ideally train it for a larger amount of epochs than 50.\n",
        "\n",
        "That way you will get better text generation at the end.\n",
        "\n",
        "However, dont waste your time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "AIg2f1HBxqof",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885f5d84-563e-4e2b-c87c-001f8a02dee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 2s 9ms/step - loss: 4.4012 - accuracy: 0.3500\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.1246 - accuracy: 0.9800\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.9304 - accuracy: 0.9800\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.7611 - accuracy: 0.9800\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.6017 - accuracy: 0.9800\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.4407 - accuracy: 0.9800\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.2817 - accuracy: 0.9800\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 3.1156 - accuracy: 0.9800\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.9473 - accuracy: 0.9800\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.7788 - accuracy: 0.9800\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.6138 - accuracy: 0.9800\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.4525 - accuracy: 0.9800\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.2960 - accuracy: 0.9800\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.1454 - accuracy: 0.9800\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.9997 - accuracy: 0.9800\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.8596 - accuracy: 0.9800\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.7273 - accuracy: 0.9800\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.5999 - accuracy: 0.9800\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.4800 - accuracy: 0.9800\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.3676 - accuracy: 0.9800\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.2628 - accuracy: 0.9800\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1647 - accuracy: 0.9800\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0750 - accuracy: 0.9800\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9921 - accuracy: 0.9800\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9166 - accuracy: 0.9800\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.8480 - accuracy: 0.9800\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7853 - accuracy: 0.9800\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7299 - accuracy: 0.9800\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.9800\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.9800\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5924 - accuracy: 0.9800\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5555 - accuracy: 0.9800\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.9800\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.9800\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4651 - accuracy: 0.9800\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.9800\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.9800\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.9800\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.9800\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3644 - accuracy: 0.9800\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.9800\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3355 - accuracy: 0.9800\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3232 - accuracy: 0.9800\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3119 - accuracy: 0.9800\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.9800\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2919 - accuracy: 0.9800\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2830 - accuracy: 0.9800\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2748 - accuracy: 0.9800\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2671 - accuracy: 0.9800\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2600 - accuracy: 0.9800\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(predictors, label, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V1ENCPLSdRE"
      },
      "source": [
        "# Use plt from matplotlib to plot the training accuracy over epochs and the loss over epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1yGW9p0SdRE"
      },
      "source": [
        "First you will have to get the accuracy and loss data over epochs, you can do this by using methods on your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "03f5e6e9-a11c-4e88-9c27-7ac091b269d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d27a0389ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get training accuracy and loss values from the history object\n",
        "training_accuracy = history.history['accuracy']\n",
        "training_loss = history.history['loss']\n",
        "\n",
        "# Create the plot for accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(training_accuracy, label='Training Accuracy')\n",
        "plt.title('Training Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Create the plot for loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(training_loss, label='Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8PFz7moSdRE"
      },
      "source": [
        "# Generate text with the model based on a seed text\n",
        "\n",
        "Now you will create two variables :\n",
        "\n",
        "- seed_text = 'Write the text you want the model to use as a starting point to generate the next words'\n",
        "- next_words = number_of_words_you_want_the_model_to_generate\n",
        "\n",
        "Please change number_of_words_you_want_the_model_to_generate by an actual integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "51-GPTWmSdRE"
      },
      "outputs": [],
      "source": [
        "seed_text = \"Write the text you want the model to use as a starting point to generate the next words\"\n",
        "next_words = 50  # Generate 50 words after the seed text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWGZot6ASdRE"
      },
      "source": [
        "Now create a loop that runs based on the next_words variable and generates new text based on your seed_text input string. Print the full text with the generated text at the end.\n",
        "\n",
        "This time you dont get detailed instructions.\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7e7349-f594-4c79-c460-e4dae95de651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Write the text you want the model to use as a starting point to generate the next words <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # Import numpy for array operations\n",
        "\n",
        "\n",
        "def generate_text(seed_text, next_words, model, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        # Tokenize the seed text\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "        # Pad the token_list to have the expected sequence length (9 in this case)\n",
        "        token_list = np.pad(token_list, (0, 9 - len(token_list)), 'constant')\n",
        "\n",
        "        # Reshape the token_list to have the expected 2D shape\n",
        "        token_list = np.reshape(token_list, (1, 9)) # Reshape to (1, sequence_length)\n",
        "\n",
        "        # Predict the next word\n",
        "        predicted_probs = model.predict(token_list)\n",
        "        predicted_id = np.argmax(predicted_probs, axis=-1)\n",
        "\n",
        "        # Get the actual word from the predicted ID\n",
        "        # Check if the predicted ID is in the tokenizer's vocabulary\n",
        "        # If not present, use a default word or handle the unknown token\n",
        "        output_word = tokenizer.index_word.get(predicted_id[0], '<UNK>')\n",
        "\n",
        "        # Append the predicted word to the seed text\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Generate and print the text\n",
        "generated_text = generate_text(seed_text, next_words, model, tokenizer)  # Assume tokenizer is defined\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0WksKI5SdRF"
      },
      "source": [
        "Experiment with at least 3 different seed_text strings and see what happens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkvQNm4ZSdRF",
        "outputId": "ce6deaed-392a-4d1a-e02f-48918aaaefa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Seed Text: The quick brown fox jumps over the\n",
            "Generated Text: The quick brown fox jumps over the <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Seed Text: Once upon a time there was a\n",
            "Generated Text: Once upon a time there was a <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Seed Text: In a galaxy far far away\n",
            "Generated Text: In a galaxy far far away <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
            "\n",
            "\n",
            "1/1 [==============================] - 0s 368ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Seed Text: Hello, how are you doing\n",
            "Generated Text: Hello, how are you doing <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_text(seed_text, next_words, model, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = np.pad(token_list, (0, 9 - len(token_list)), 'constant')\n",
        "        token_list = np.reshape(token_list, (1, 9))\n",
        "        predicted_probs = model.predict(token_list)\n",
        "        predicted_id = np.argmax(predicted_probs, axis=-1)\n",
        "        output_word = tokenizer.index_word.get(predicted_id[0], '<UNK>')\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Different seed texts to try\n",
        "seed_texts = [\n",
        "    \"The quick brown fox jumps over the\",\n",
        "    \"Once upon a time there was a\",\n",
        "    \"In a galaxy far far away\",\n",
        "    \"Hello, how are you doing\"\n",
        "]\n",
        "\n",
        "# Generate and print text for each seed text\n",
        "for seed_text in seed_texts:\n",
        "    next_words = 50\n",
        "    generated_text = generate_text(seed_text, next_words, model, tokenizer)\n",
        "    print(f\"Seed Text: {seed_text}\\nGenerated Text: {generated_text}\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Week4_Exercise_Shakespeare_Answer.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}